---
title: "Sensor fusion in GGIR"
author: "Vincent van Hees"
date: "February 10 2021"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
urlcolor: blue
vignette: >
  %\VignetteIndexEntry{Sensor fusion in GGIR}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}
    \includegraphics[]{GGIR-MASTERLOGO-RGB.png}\LARGE\\}
  - \posttitle{\end{center}}
---

# Introduction

Wearable sensors that combine acceleration and gyroscope sensors have become feasible for use for physical behaviour research. In this field wearable sensors are typically worn for at least a week, while raw data is being stored for later offline analysis. R package GGIR originated from the need to process accelerometer-only data in the 2010s. However, with the expected additional availability of gyroscope data in the upcoming years it is important that GGIR's functionality is expanded to also handle gyroscope data.

For health researchers with no background in sensor technology it may be important to explain that gyroscopes measures angular velocity (the speed at which the sensor rotates). This information can help us to reach a more accurate estimate of the magnitude of acceleration and sensor orientation relative to the direction of gravity (vertical). You may not be aware of this, but acceleormeter-only applications have always had the fundamental limitation that they were not capable of distinguishing acceleration caused by gravity and acceleration caused by movement while the sensor is moving and rotating relative to the gravity. See also the work my colleagues and I did on this and described in our [2013 PLOSONE publication](link to pa(https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061691).

To extract the improved estimate of movement-related acceleration we need to combine information from both the acceleration- and gyroscope signals, which is typically referred to as sensor fusion.

# Requirements

In my exploration of possible solutions for doing sensor fusion GGIR I identified the following criteria:
- The algorithm should be fast enough to process a week worth of 100 Hertz  sensor data. We can wait a few minutes and maybe half an hour, but ideally we want to avoid having to wait for hours or days to process a single file.
- The primary focus for GGIR would be to quantify acceleration related to movement with improved separation of the gravitational signal component. A more elaborate kinematic description feels to me as less essential within the context of GGIR.

# Initial exploration of existing algorithms

Various sensor fusion algorithms have been proposed in the literature. However, I found it hard to implement any of them quickly. I spent a couple of days exploring the algorithms proposed by Luinge and Veltink in 2005, and the one proposed by [Madgewick in 2009](https://x-io.co.uk/open-source-imu-and-ahrs-algorithms/). However, I struggled to either get them to run within an R environment at an acceptable speed. Further, I found it difficult to translate their output to an estimate of local (gravity free) acceleration. So, I decided to develop my own algorithm tailored to the needs of GGIR. In this way I challenged myself to learn about this topic and it has allowed me to make a starting point with facilitating sensor fusion in GGIR. GGIR is an open source project, so I welcome help to develop and improve this functionality. Please get in touch if you are interested: v.vanhees@accelting.com.

In this document I have tried to describe and motivate every step of my algorithm, which I implemented in GGIR function `separategravity`. 

# Algorithm description

## Input

The input of the algorithm consists of three objects: `acc`, a three column matrix with the accelerometer values in *g*-units; `gyr`, a three column matrix with the gyroscope values in radians per second, and; `sf` the sample frequency in Hertz. The algorithm assumes a constant sample frequency througout the recording. Please note that GGIR has function `resample` to aid in converting irregularly samples data to a regular sample frequency.

## Coordinate system

All calculations will be done within the local coordinate system of the sensor. In contrast to other algorithms I am not attempting to calculate roll, pitch or yaw, because calculating those would require transitioning between multiple coordinate systems. For example, pitch derived from a gyroscope is always in a local coordinate system, while pitch derived from an accelerometer is relative to the orientation of gravity. So, to me it does not sound logical to use pitch, roll, and yaw as the starting point for the fusion. Instead, I will derive the orientation of gravity relative to the local coordinate system and use the angular velocity relative to the local coordinate system to rotate the orientation of the gravity vector during movement. By tracking the orientation of gravity within the local coordinate system of the sensor I will be able to subtract gravity from the acceleration signals.

## Angular velocity vector

The gyroscope signals represent angular velocity in radians per second. As I want to rotate the gravitational acceleration vector I need to split the gyroscope signals up in an angular velocity vector with a magnitude (`theta` in the code) per time step and 3 coordinates for the vector orientation (object `OV` in the code) relative to the sensors coordinate system. 

```{R,eval=FALSE}
theta = sqrt(rowSums(gyr ^ 2)) # theta (magnitude of angular velocity around orientation vector OV)
OV = matrix(0, N, 3) # N is number of samples.
nozero = which(theta > 0)
OV[nozero,] = as.numeric(gyr[nozero,] / theta[nozero])
```

Next, theta is divided by the sample frequency to get radians per time step.

```{R,eval=FALSE}
theta = theta / sf
```

## Derivation of fusion weights

Weights are used to decide for each time step the extent to which we want to rely on the accelerometer or on the gyroscope for orientation assessment. I decided to use the high-frequency component of the signal as indicator of movement. However, later on I will need a low-pass filtered signal as indicator of sensor orientation during static (non-movement periods). So, to safe computational time I apply a low-pass filter and subtract it from the original signal to get the high-pass filtered signals.

```{R,eval=FALSE}
lb = 0.5 # cut-off frequency for the filter in Hertz
lowpf = signal::butter(n=4,c(lb/(sf/2)),type=c("low")) #creating filter coefficients
acc_lf = acc_hf = matrix(NA, nrow(acc), ncol(acc)) # initialize matrices
for (i in 1:3) {
    # note: acc_lf will also be used as assume orientation of gravity in the
    # absence of movement further down, so this calculate serves two purposes
    acc_lf[,i] <- signal::filter(lowpf, acc[,i]) # low-pass filtered
}
acc_hf <- acc - acc_lf # high-pass filtered
```

Weights are expressed on a scale between 0 and 1, where 0 indictates full dependence on accelerometer, and 1 indicates full dependence on gyroscope. When the summed acceleration of the three axis is less than 0.04g the weight is set to 0. The threshold of 0.04g reflects the assumed combined noise of the three acceleration signals. The following code has build in a minor ramp from 0.04 to 0.05. When the summed acceleration is above 0.05 the weight is set to 1. 

```{R,eval=FALSE}
weight = pmin(pmax((rowSums(abs(acc_hf)) - 0.04),0) / 0.01, 1) 
```

### Maximum weight value

By setting the maximum weight value to 1-(0.5/sf) I ensure that there is always a negative exponential drift from gyroscope estimate to the accelerometer estimate. This to counteract a possible drift in the gyroscope derived orientation change. Here, I am making the assumption that even under dynamic circumstances the low-pass filtered acceleration signal averaged across multiple seconds provides some indication of the average orientation of the sensor during that period.


```{R,eval=FALSE}
maxweight = 1-(0.5/sf)
weight = ifelse(weight > maxweight, yes = maxweight, no = weight)
```


### Minimum non-zero weight value

By setting a minimum non-zero weight value to 0.01, and rounding all values below 0.01 to 1, I ensure make that the fusion is skipped when the gyroscope contribution is small. This to speed up the algorithm.

```{R,eval=FALSE}
weight = ifelse(weight < 0.01, yes = 0, no = weight)
```

## Rotation vector

To rotate the orientation vector of gravity we need to convert `theta` and `OV` into a rotation matrix.

Note that this is a standard textbook procedure:
https://stackoverflow.com/questions/6721544/circular-rotation-around-an-arbitrary-axis 

```{R,eval=FALSE}
  RotArr = array(dim = c(N, 3, 3)) # this is a rotation matrix for every timestep
  costheta = cos(theta)
  sintheta = sin(theta)
  RotArr[,1,1:3] = cbind(costheta +
                           OV[,1]^2 * (1-costheta), OV[,1] * OV[,2] * (1- costheta) -
                           OV[,3] * sintheta, OV[,1] * OV[,3] * (1- costheta) +
                           OV[,2] * sintheta)
  RotArr[,2,1:3] = cbind(OV[,2] * OV[,1] * (1- costheta) +
                           OV[,3] * sintheta, costheta +
                           OV[,2]^2 * (1-costheta),OV[,2] * OV[,3] * (1- costheta) -
                           OV[,1] * sintheta)
  RotArr[,3,1:3] = cbind(OV[,3] * OV[,1] * (1- costheta) -
                           OV[,2] * sintheta, OV[,3] * OV[,2] * (1- costheta) +
                           OV[,1] * sintheta,  costheta +
                           OV[,3]^2 * (1-costheta))
```
  
## Rotating the gravity vector

In the follow lines I loop over the non-zero weight values to rotate the gravitational vector
within the local coordinate system. Note that this is an iterative process, each step depends on the previous step, which is why I am using a loop and not an `apply` statement in R. If you have suggestions on how I could spit this up then get in touch.

```{R,eval=FALSE}
gvector = acc_lf # initialize gvector as equivalent of acc_lf
weight_not_zero = which(weight > 0)
if (weight_not_zero[1] == 1) weight_not_zero = weight_not_zero[2:length(weight_not_zero)]
for (j in weight_not_zero) {
  gvector[j,] = (crossprod(RotArr[j-1,,],  gvector[j-1,]) * weight[j]) +
    (acc_lf[j,] * (1-weight[j]))
}
acclocal = acc - gvector
```


# Using the algorithm with GGIR

At the moment I have implemented the functionality to work with the .cwa data from the AX6 sensor by Axivity Ltd.
While running the central GGIR function `g.shell.GGIR` the code will automatically extract metric `sgAccEN`, which is the average of the local magnitude of acceleration based on the fused data.

# Performance

## Speed

With a virtual machine (Ubuntu 20, 4 core, and 8GB):

Recording duration (hours) at 100 Hertz | Processing time
-------------------- | --------------------------
1 hour | 1.25 seconds
2 hour | 2.00 seconds
4 hour | 3.80 seconds
12 hour | 10.34 seconds
24 hour | 10.34 seconds

## Accuracy

I did some simple home experiments to check the output. However, a thorough benchmark test has not been done yet. If you are interested in doing this work then get in touch: v.vanhees@accelting.com.

# Relation with accelerometer-only metrics

For accelerometer-only metrics it has traditionally been difficult to assess how good these metrics are.
The fused sensor data now offers us a more reliable reference point for compare accelerometer-only metrics for the magnitude of movement-related acceleration. I have extracted all metrics from the [2013 PLOSONE publication](link to pa(https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061691) I mentioned above, which let to the following correlation with `sgAccEN`.

Accelerometer-only metric | Correlation with sgAccEN
-------------------- | -------------------- 
ENMO |
ENMOa
MAD
HFEN
HFENplus

